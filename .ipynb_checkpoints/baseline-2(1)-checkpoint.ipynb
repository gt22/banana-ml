{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтение датасетов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('bfd/train_dataset.csv')\n",
    "df = df[(~df.TailNum.isnull()) & (~df.DepTime.isnull()) & (~df.AirTime.isnull())]\n",
    "\n",
    "test = pd.read_csv('bfd/test_dataset.csv').replace([np.nan, np.inf, -np.inf], 0)\n",
    "test_ids = test.Id.values\n",
    "test.drop('Id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считаем простые признаки. Одновременно для трейн и тест выборок. Так меньше шансов ошибиться"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['speed'] = (60 * df.Distance/df.AirTime).replace([np.nan, np.inf, -np.inf], 0)\n",
    "test['speed'] = (60 * test.Distance/test.AirTime).replace([np.nan, np.inf, -np.inf], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['diff_arr_dep_time'] = df.ArrTime - df.DepTime\n",
    "test['diff_arr_dep_time'] = test.ArrTime - test.DepTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['elapsed_time'] = df.ArrTime + df.TaxiIn + df.TaxiOut\n",
    "test['elapsed_time'] = test.ArrTime + test.TaxiIn + test.TaxiOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def season(x):\n",
    "    if x in [12, 1, 2]:\n",
    "        return 'winter'\n",
    "    elif x in [3,4,5]:\n",
    "        return 'spring'\n",
    "    elif x in [6,7,8]:\n",
    "        return 'summer'\n",
    "    else:\n",
    "        return 'fall'\n",
    "\n",
    "df['season'] = df.Month.apply(lambda x: season(x))\n",
    "test['season'] = test.Month.apply(lambda x: season(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timefl(x):\n",
    "    begin = x['DepTime']\n",
    "    end = x['ArrTime']\n",
    "    if end < begin :\n",
    "        end += 2400\n",
    "    bh = int(begin/100)\n",
    "    eh = int(end/100)\n",
    "    bm = int(begin%100)\n",
    "    em = int(end%100)\n",
    "    answerm = (eh - bh)*60 + em - bm\n",
    "    return answerm\n",
    "\n",
    "df['FullTime'] = df.apply(timefl, axis = 1)\n",
    "test['FullTime'] = df.apply(timefl, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перемешиваем датасет и разбиваем на 2 части. По одной части будем насчитывать статистику, а на другой будем обучать модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2399348, 21) (1028292, 21)\n"
     ]
    }
   ],
   "source": [
    "df = shuffle(df)\n",
    "\n",
    "x_count, x_train = train_test_split(df, test_size=0.3, random_state=42)\n",
    "print(x_count.shape, x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дальше будет код для подсчета эмпирического(наблюдаемого) среднего по различным признакам. Обычно вместо того чтобы использовать среднее по историческим данным, используют так называемые <b>log odds</b>. Подумайте почему :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def logit(x):\n",
    "    return math.log((x / (1-x)) + 1e-5)\n",
    "\n",
    "def logit_vec(v):\n",
    "    return logit(v.mean()) # guess why ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>day_mean_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.835960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.983972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.987045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.840462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>-0.681037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DayOfWeek  day_mean_target\n",
       "0          1        -0.835960\n",
       "1          2        -0.983972\n",
       "2          3        -0.987045\n",
       "3          4        -0.840462\n",
       "4          5        -0.681037"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day_mean = df.loc[:, ['DayOfWeek', 'target']].groupby('DayOfWeek').agg(logit_vec).reset_index()\n",
    "day_mean.rename(columns={'target': 'day_mean_target'}, inplace=True)\n",
    "day_mean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>month_mean_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.716806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.563873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.612841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.947695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>-0.985031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Month  month_mean_target\n",
       "0      1          -0.716806\n",
       "1      2          -0.563873\n",
       "2      3          -0.612841\n",
       "3      4          -0.947695\n",
       "4      5          -0.985031"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "month_mean = df.loc[:, ['Month', 'target']].groupby('Month').agg(logit_vec).reset_index()\n",
    "month_mean.rename(columns={'target': 'month_mean_target'}, inplace=True)\n",
    "month_mean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UniqueCarrier</th>\n",
       "      <th>flight_carrier_volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9E</td>\n",
       "      <td>0.208778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AA</td>\n",
       "      <td>0.490782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AQ</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AS</td>\n",
       "      <td>0.119449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B6</td>\n",
       "      <td>0.156475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  UniqueCarrier  flight_carrier_volume\n",
       "0            9E               0.208778\n",
       "1            AA               0.490782\n",
       "2            AQ               0.000000\n",
       "3            AS               0.119449\n",
       "4            B6               0.156475"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flight_c_volume = df.loc[:, ['target', 'UniqueCarrier']].groupby(['UniqueCarrier']).agg('count').reset_index()\n",
    "flight_c_volume.rename(columns={'target': 'flight_carrier_volume'}, inplace=True)\n",
    "flight_c_volume['flight_carrier_volume'] = scaler.fit_transform(flight_c_volume['flight_carrier_volume'].reshape(-1,1))\n",
    "flight_c_volume.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TailNum</th>\n",
       "      <th>flight_volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80009E</td>\n",
       "      <td>0.390379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80019E</td>\n",
       "      <td>0.395913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>80059E</td>\n",
       "      <td>0.395913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80129E</td>\n",
       "      <td>0.407407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>80139E</td>\n",
       "      <td>0.398467</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  TailNum  flight_volume\n",
       "0  80009E       0.390379\n",
       "1  80019E       0.395913\n",
       "2  80059E       0.395913\n",
       "3  80129E       0.407407\n",
       "4  80139E       0.398467"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flight_volume = df.loc[:, ['target', 'TailNum']].groupby(['TailNum']).agg('count').reset_index()\n",
    "flight_volume.rename(columns={'target': 'flight_volume'}, inplace=True)\n",
    "flight_volume['flight_volume'] = scaler.fit_transform(flight_volume['flight_volume'].reshape(-1,1))\n",
    "flight_volume.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>season_empirical_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fall</td>\n",
       "      <td>-1.363724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spring</td>\n",
       "      <td>-0.845076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>summer</td>\n",
       "      <td>-0.770963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>winter</td>\n",
       "      <td>-0.562199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   season  season_empirical_mean\n",
       "0    fall              -1.363724\n",
       "1  spring              -0.845076\n",
       "2  summer              -0.770963\n",
       "3  winter              -0.562199"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "season = x_count.loc[:, ['target', 'season']].groupby('season').agg(logit_vec).reset_index()\n",
    "season.rename(columns={'target': 'season_empirical_mean'}, inplace=True)\n",
    "season.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UniqueCarrier</th>\n",
       "      <th>un_carrier_empirical_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9E</td>\n",
       "      <td>-1.311483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AA</td>\n",
       "      <td>-0.661085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AQ</td>\n",
       "      <td>-2.104625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AS</td>\n",
       "      <td>-0.948923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B6</td>\n",
       "      <td>-0.859654</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  UniqueCarrier  un_carrier_empirical_mean\n",
       "0            9E                  -1.311483\n",
       "1            AA                  -0.661085\n",
       "2            AQ                  -2.104625\n",
       "3            AS                  -0.948923\n",
       "4            B6                  -0.859654"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "un_carrier = x_count.loc[:, ['target', 'UniqueCarrier']].groupby('UniqueCarrier').agg(logit_vec).reset_index()\n",
    "un_carrier.rename(columns={'target': 'un_carrier_empirical_mean'}, inplace=True)\n",
    "un_carrier.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Origin', 'target'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Origin</th>\n",
       "      <th>origin_empirical_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABE</td>\n",
       "      <td>-1.283641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABI</td>\n",
       "      <td>-1.660410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABQ</td>\n",
       "      <td>-0.948466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABY</td>\n",
       "      <td>-0.962785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACK</td>\n",
       "      <td>-0.039210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Origin  origin_empirical_mean\n",
       "0    ABE              -1.283641\n",
       "1    ABI              -1.660410\n",
       "2    ABQ              -0.948466\n",
       "3    ABY              -0.962785\n",
       "4    ACK              -0.039210"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "origin = x_count.loc[:, ['target', 'Origin']].groupby('Origin').agg(logit_vec).reset_index()\n",
    "print(origin.columns)\n",
    "origin.rename(columns={'target': 'origin_empirical_mean'}, inplace=True)\n",
    "origin.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dest</th>\n",
       "      <th>dest_empirical_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABE</td>\n",
       "      <td>-0.928064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABI</td>\n",
       "      <td>-0.613735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABQ</td>\n",
       "      <td>-0.743714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABY</td>\n",
       "      <td>-0.737940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACK</td>\n",
       "      <td>-0.514439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Dest  dest_empirical_mean\n",
       "0  ABE            -0.928064\n",
       "1  ABI            -0.613735\n",
       "2  ABQ            -0.743714\n",
       "3  ABY            -0.737940\n",
       "4  ACK            -0.514439"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dest = x_count.loc[:, ['target', 'Dest']].groupby('Dest').agg(logit_vec).reset_index()\n",
    "dest.rename(columns={'target': 'dest_empirical_mean'}, inplace=True)\n",
    "dest.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По некоторым самолётам очень мало статистики. Поэтому здесь нужно либо воспользоваться обычным средним, либо размышлять над тем как сгладить средее. Поскольку это код бейзлайна, я просто воспользуюсь средним."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TailNum</th>\n",
       "      <th>tailnum_empirical_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80009E</td>\n",
       "      <td>0.214626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80019E</td>\n",
       "      <td>0.208145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>80059E</td>\n",
       "      <td>0.217195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80129E</td>\n",
       "      <td>0.221726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>80139E</td>\n",
       "      <td>0.201238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  TailNum  tailnum_empirical_mean\n",
       "0  80009E                0.214626\n",
       "1  80019E                0.208145\n",
       "2  80059E                0.217195\n",
       "3  80129E                0.221726\n",
       "4  80139E                0.201238"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tailnum = x_count.loc[:, ['target', 'TailNum']].groupby('TailNum').agg('mean').reset_index()\n",
    "tailnum.rename(columns={'target': 'tailnum_empirical_mean'}, inplace=True)\n",
    "tailnum.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1028281, 32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = pd.merge(x_train, season, on=['season'])\n",
    "x_train = pd.merge(x_train, un_carrier, on=['UniqueCarrier'])\n",
    "x_train = pd.merge(x_train, origin, on=['Origin'])\n",
    "x_train = pd.merge(x_train, dest, on=['Dest'])\n",
    "x_train = pd.merge(x_train, tailnum, on=['TailNum'])\n",
    "x_train = pd.merge(x_train, flight_volume, on=['TailNum'])\n",
    "x_train = pd.merge(x_train, month_mean, on=['Month'])\n",
    "x_train = pd.merge(x_train, day_mean, on=['DayOfWeek'])\n",
    "x_train = pd.merge(x_train, flight_c_volume, on=['UniqueCarrier'])\n",
    "\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = shuffle(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем пользоваться только перечисленными ниже фичами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numeric_features = [\n",
    "    'Month',\n",
    "    'DayofMonth',\n",
    "    'DayOfWeek',\n",
    "    'DepTime',\n",
    "    'ArrTime',\n",
    "    'AirTime',\n",
    "    'Distance',\n",
    "    'TaxiIn',\n",
    "    'TaxiOut'\n",
    "]\n",
    "\n",
    "numeric_features += ['FullTime',\n",
    "                     'elapsed_time',\n",
    "                     'diff_arr_dep_time',\n",
    "                     'speed',\n",
    "                     'season_empirical_mean',\n",
    "                     'un_carrier_empirical_mean', \n",
    "                     'origin_empirical_mean', \n",
    "                     'dest_empirical_mean',\n",
    "                     'tailnum_empirical_mean',\n",
    "                     'flight_volume',\n",
    "                     'day_mean_target',\n",
    "                     'month_mean_target',\n",
    "                     'flight_carrier_volume']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test2 = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3504864, 37)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.merge(test, season, on=['season'], how='left')\n",
    "test = pd.merge(test, un_carrier, on=['UniqueCarrier'], how='left')\n",
    "test = pd.merge(test, origin, on=['Origin'], how='left')\n",
    "test = pd.merge(test, dest, on=['Dest'], how='left')\n",
    "test = pd.merge(test, tailnum, on=['TailNum'], how='left')\n",
    "test = pd.merge(test, flight_volume, on=['TailNum'], how='left')\n",
    "test = pd.merge(test, month_mean, on=['Month'], how='left')\n",
    "test = pd.merge(test, day_mean, on=['DayOfWeek'], how='left')\n",
    "test = pd.merge(test, flight_c_volume, on=['UniqueCarrier'], how='left')\n",
    "\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1028281, 23) (3504864, 22)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>DayofMonth</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>DepTime</th>\n",
       "      <th>ArrTime</th>\n",
       "      <th>AirTime</th>\n",
       "      <th>Distance</th>\n",
       "      <th>TaxiIn</th>\n",
       "      <th>TaxiOut</th>\n",
       "      <th>FullTime</th>\n",
       "      <th>...</th>\n",
       "      <th>season_empirical_mean</th>\n",
       "      <th>un_carrier_empirical_mean</th>\n",
       "      <th>origin_empirical_mean</th>\n",
       "      <th>dest_empirical_mean</th>\n",
       "      <th>tailnum_empirical_mean</th>\n",
       "      <th>flight_volume</th>\n",
       "      <th>day_mean_target</th>\n",
       "      <th>month_mean_target</th>\n",
       "      <th>flight_carrier_volume</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>140157</th>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1849.0</td>\n",
       "      <td>1920.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>935</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.068720</td>\n",
       "      <td>-1.039568</td>\n",
       "      <td>0.307787</td>\n",
       "      <td>0.489144</td>\n",
       "      <td>-0.835960</td>\n",
       "      <td>-1.378760</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950143</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>1706.0</td>\n",
       "      <td>1932.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>264</td>\n",
       "      <td>27.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>146</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.177351</td>\n",
       "      <td>-0.965937</td>\n",
       "      <td>0.268166</td>\n",
       "      <td>0.349085</td>\n",
       "      <td>-0.983972</td>\n",
       "      <td>-1.287725</td>\n",
       "      <td>0.370244</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655384</th>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "      <td>1421.0</td>\n",
       "      <td>1557.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>866</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>96</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.079229</td>\n",
       "      <td>-1.228544</td>\n",
       "      <td>0.276404</td>\n",
       "      <td>0.277139</td>\n",
       "      <td>-0.947283</td>\n",
       "      <td>-0.612841</td>\n",
       "      <td>0.301651</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538960</th>\n",
       "      <td>8</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>947.0</td>\n",
       "      <td>1211.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>919</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>144</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.763227</td>\n",
       "      <td>-0.883898</td>\n",
       "      <td>0.285505</td>\n",
       "      <td>0.417625</td>\n",
       "      <td>-0.681037</td>\n",
       "      <td>-0.919968</td>\n",
       "      <td>0.212929</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804776</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2138.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>293.0</td>\n",
       "      <td>2466</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>491</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.226517</td>\n",
       "      <td>-1.217491</td>\n",
       "      <td>0.272277</td>\n",
       "      <td>0.256279</td>\n",
       "      <td>-0.835960</td>\n",
       "      <td>-0.791903</td>\n",
       "      <td>0.285397</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Month  DayofMonth  DayOfWeek  DepTime  ArrTime  AirTime  Distance  \\\n",
       "140157     10          20          1   1849.0   1920.0    139.0       935   \n",
       "950143     11          11          2   1706.0   1932.0     50.0       264   \n",
       "655384      3          29          6   1421.0   1557.0    143.0       866   \n",
       "538960      8          29          5    947.0   1211.0    128.0       919   \n",
       "804776      7           7          1   2138.0    549.0    293.0      2466   \n",
       "\n",
       "        TaxiIn  TaxiOut  FullTime   ...    season_empirical_mean  \\\n",
       "140157     6.0      6.0        31   ...                      NaN   \n",
       "950143    27.0      9.0       146   ...                      NaN   \n",
       "655384     2.0     11.0        96   ...                      NaN   \n",
       "538960     4.0     12.0       144   ...                      NaN   \n",
       "804776     6.0     12.0       491   ...                      NaN   \n",
       "\n",
       "        un_carrier_empirical_mean  origin_empirical_mean  dest_empirical_mean  \\\n",
       "140157                        NaN              -1.068720            -1.039568   \n",
       "950143                        NaN              -1.177351            -0.965937   \n",
       "655384                        NaN              -1.079229            -1.228544   \n",
       "538960                        NaN              -0.763227            -0.883898   \n",
       "804776                        NaN              -1.226517            -1.217491   \n",
       "\n",
       "        tailnum_empirical_mean  flight_volume  day_mean_target  \\\n",
       "140157                0.307787       0.489144        -0.835960   \n",
       "950143                0.268166       0.349085        -0.983972   \n",
       "655384                0.276404       0.277139        -0.947283   \n",
       "538960                0.285505       0.417625        -0.681037   \n",
       "804776                0.272277       0.256279        -0.835960   \n",
       "\n",
       "        month_mean_target  flight_carrier_volume  target  \n",
       "140157          -1.378760               1.000000       0  \n",
       "950143          -1.287725               0.370244       0  \n",
       "655384          -0.612841               0.301651       0  \n",
       "538960          -0.919968               0.212929       0  \n",
       "804776          -0.791903               0.285397       0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = x_train.loc[:, numeric_features + ['target']]\n",
    "test = test.loc[:, numeric_features]\n",
    "print(x_train.shape, test.shape)\n",
    "x_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Кросс валидация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обычно её делают так"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "JoblibValueError",
     "evalue": "JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\nA:\\Anaconda3\\lib\\runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\nA:\\Anaconda3\\lib\\runpy.py in _run_code(code=<code object <module> at 0x000001C59263DC90, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'A:\\Anaconda3\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'A:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'A:\\\\Anaconda3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x000001C59263DC90, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'A:\\Anaconda3\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'A:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'A:\\\\Anaconda3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\nA:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\nA:\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\nA:\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    472             return self.subapp.start()\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         try:\n--> 477             ioloop.IOLoop.instance().start()\n    478         except KeyboardInterrupt:\n    479             pass\n    480 \n    481 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\nA:\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\nA:\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\nA:\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\nA:\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\nA:\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\nA:\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\nA:\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\nA:\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\nA:\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'cv = cross_val_score(estimator=LogisticRegressio... n_jobs=-1,)\\nprint(cv.mean(), cv.std())\\nprint(cv)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 2, 24, 18, 55, 57, 492250, tzinfo=tzutc()), 'msg_id': '477830FF1DBF499885B7307851B82494', 'msg_type': 'execute_request', 'session': '6D8CFF996F07448DB708A867FE8C7AC1', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '477830FF1DBF499885B7307851B82494', 'msg_type': 'execute_request', 'parent_header': {}})\n    230             self.log.warn(\"Unknown message type: %r\", msg_type)\n    231         else:\n    232             self.log.debug(\"%s: %s\", msg_type, msg)\n    233             self.pre_handler_hook()\n    234             try:\n--> 235                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'6D8CFF996F07448DB708A867FE8C7AC1']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'cv = cross_val_score(estimator=LogisticRegressio... n_jobs=-1,)\\nprint(cv.mean(), cv.std())\\nprint(cv)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 2, 24, 18, 55, 57, 492250, tzinfo=tzutc()), 'msg_id': '477830FF1DBF499885B7307851B82494', 'msg_type': 'execute_request', 'session': '6D8CFF996F07448DB708A867FE8C7AC1', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '477830FF1DBF499885B7307851B82494', 'msg_type': 'execute_request', 'parent_header': {}}\n    236             except Exception:\n    237                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    238             finally:\n    239                 self.post_handler_hook()\n\n...........................................................................\nA:\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'6D8CFF996F07448DB708A867FE8C7AC1'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'cv = cross_val_score(estimator=LogisticRegressio... n_jobs=-1,)\\nprint(cv.mean(), cv.std())\\nprint(cv)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 2, 24, 18, 55, 57, 492250, tzinfo=tzutc()), 'msg_id': '477830FF1DBF499885B7307851B82494', 'msg_type': 'execute_request', 'session': '6D8CFF996F07448DB708A867FE8C7AC1', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '477830FF1DBF499885B7307851B82494', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\nA:\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='cv = cross_val_score(estimator=LogisticRegressio... n_jobs=-1,)\\nprint(cv.mean(), cv.std())\\nprint(cv)', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = 'cv = cross_val_score(estimator=LogisticRegressio... n_jobs=-1,)\\nprint(cv.mean(), cv.std())\\nprint(cv)'\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\nA:\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('cv = cross_val_score(estimator=LogisticRegressio... n_jobs=-1,)\\nprint(cv.mean(), cv.std())\\nprint(cv)',), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('cv = cross_val_score(estimator=LogisticRegressio... n_jobs=-1,)\\nprint(cv.mean(), cv.std())\\nprint(cv)',)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\nA:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='cv = cross_val_score(estimator=LogisticRegressio... n_jobs=-1,)\\nprint(cv.mean(), cv.std())\\nprint(cv)', store_history=True, silent=False, shell_futures=True)\n   2693                 self.displayhook.exec_result = result\n   2694 \n   2695                 # Execute the user code\n   2696                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2697                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2698                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2699                 \n   2700                 self.last_execution_succeeded = not has_raised\n   2701 \n   2702                 # Reset this so later displayed values do not modify the\n\n...........................................................................\nA:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Expr object>, <_ast.Expr object>], cell_name='<ipython-input-44-f5a234f2c534>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 1c581f23550, executio..._before_exec=None error_in_exec=None result=None>)\n   2797 \n   2798         try:\n   2799             for i, node in enumerate(to_run_exec):\n   2800                 mod = ast.Module([node])\n   2801                 code = compiler(mod, cell_name, \"exec\")\n-> 2802                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x000001C581CF9C00, file \"<ipython-input-44-f5a234f2c534>\", line 1>\n        result = <ExecutionResult object at 1c581f23550, executio..._before_exec=None error_in_exec=None result=None>\n   2803                     return True\n   2804 \n   2805             for i, node in enumerate(to_run_interactive):\n   2806                 mod = ast.Interactive([node])\n\n...........................................................................\nA:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x000001C581CF9C00, file \"<ipython-input-44-f5a234f2c534>\", line 1>, result=<ExecutionResult object at 1c581f23550, executio..._before_exec=None error_in_exec=None result=None>)\n   2857         outflag = True  # happens in more places, so it's easier as default\n   2858         try:\n   2859             try:\n   2860                 self.hooks.pre_run_code_hook()\n   2861                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2862                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x000001C581CF9C00, file \"<ipython-input-44-f5a234f2c534>\", line 1>\n        self.user_global_ns = {'In': ['', 'import pandas as pd\\nimport numpy as np\\nfrom skle...rt MinMaxScaler\\nfrom sklearn.utils import shuffle', 'scaler = MinMaxScaler()', \"df = pd.read_csv('train_dataset.csv')\\ndf = df[(~...t.Id.values\\ntest.drop('Id', axis=1, inplace=True)\", \"df['speed'] = (60 * df.Distance/df.AirTime).repl...st.AirTime).replace([np.nan, np.inf, -np.inf], 0)\", \"df['diff_arr_dep_time'] = df.ArrTime - df.DepTim...diff_arr_dep_time'] = test.ArrTime - test.DepTime\", \"df['elapsed_time'] = df.ArrTime + df.TaxiIn + df...ime'] = test.ArrTime + test.TaxiIn + test.TaxiOut\", \"def season(x):\\n    if x in [12, 1, 2]:\\n        r...'season'] = test.Month.apply(lambda x: season(x))\", \"def timefl(x):\\n    begin = x['DepTime']\\n    end ... 1)\\ntest['FullTime'] = df.apply(timefl, axis = 1)\", 'df = shuffle(df)\\n\\nx_count, x_train = train_test_...dom_state=42)\\nprint(x_count.shape, x_train.shape)', 'import math\\ndef logit(x):\\n    return math.log(x ...   return logit(v.mean() + 0.00001) # guess why ?', \"day_mean = df.loc[:, ['DayOfWeek', 'target']].gr...'day_mean_target'}, inplace=True)\\nday_mean.head()\", \"month_mean = df.loc[:, ['Month', 'target']].grou...th_mean_target'}, inplace=True)\\nmonth_mean.head()\", 'import warnings\\nwarnings.filterwarnings(\"ignore\")', \"flight_c_volume = df.loc[:, ['target', 'UniqueCa...er_volume'].reshape(-1,1))\\nflight_c_volume.head()\", \"flight_volume = df.loc[:, ['target', 'TailNum']]...ight_volume'].reshape(-1,1))\\nflight_volume.head()\", \"season = x_count.loc[:, ['target', 'season']].gr...son_empirical_mean'}, inplace=True)\\nseason.head()\", \"un_carrier = x_count.loc[:, ['target', 'UniqueCa...empirical_mean'}, inplace=True)\\nun_carrier.head()\", \"origin = x_count.loc[:, ['target', 'Origin']].gr...gin_empirical_mean'}, inplace=True)\\norigin.head()\", \"dest = x_count.loc[:, ['target', 'Dest']].groupb...'dest_empirical_mean'}, inplace=True)\\ndest.head()\", ...], 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'MinMaxScaler': <class 'sklearn.preprocessing.data.MinMaxScaler'>, 'Out': {11:    DayOfWeek  day_mean_target\n0          1      ... 4        -0.840437\n4          5        -0.681012, 12:    Month  month_mean_target\n0      1          -0... 4          -0.947671\n4      5          -0.985007, 14:   UniqueCarrier  flight_carrier_volume\n0        ...  0.119449\n4            B6               0.156475, 15:   TailNum  flight_volume\n0  80009E       0.39037...3  80129E       0.407407\n4  80139E       0.398467, 16:    season  season_empirical_mean\n0    fall      ...       -0.770938\n3  winter              -0.562173, 17:   UniqueCarrier  un_carrier_empirical_mean\n0    ...948899\n4            B6                  -0.859630, 18: Empty DataFrame\nColumns: [index]\nIndex: [], 19:   Dest  dest_empirical_mean\n0  ABE            -0...            -0.737915\n4  ACK            -0.514413, 20:   TailNum  tailnum_empirical_mean\n0  80009E     ...       0.221726\n4  80139E                0.201238, 25:    DayOfWeek  day_mean_target\n0          1      ... 4        -0.840462\n4          5        -0.681037, ...}, '_':         Month  DayofMonth  DayOfWeek  DepTime  A...        0.285397       0  \n\n[5 rows x 23 columns], '_11':    DayOfWeek  day_mean_target\n0          1      ... 4        -0.840437\n4          5        -0.681012, '_12':    Month  month_mean_target\n0      1          -0... 4          -0.947671\n4      5          -0.985007, '_14':   UniqueCarrier  flight_carrier_volume\n0        ...  0.119449\n4            B6               0.156475, '_15':   TailNum  flight_volume\n0  80009E       0.39037...3  80129E       0.407407\n4  80139E       0.398467, '_16':    season  season_empirical_mean\n0    fall      ...       -0.770938\n3  winter              -0.562173, ...}\n        self.user_ns = {'In': ['', 'import pandas as pd\\nimport numpy as np\\nfrom skle...rt MinMaxScaler\\nfrom sklearn.utils import shuffle', 'scaler = MinMaxScaler()', \"df = pd.read_csv('train_dataset.csv')\\ndf = df[(~...t.Id.values\\ntest.drop('Id', axis=1, inplace=True)\", \"df['speed'] = (60 * df.Distance/df.AirTime).repl...st.AirTime).replace([np.nan, np.inf, -np.inf], 0)\", \"df['diff_arr_dep_time'] = df.ArrTime - df.DepTim...diff_arr_dep_time'] = test.ArrTime - test.DepTime\", \"df['elapsed_time'] = df.ArrTime + df.TaxiIn + df...ime'] = test.ArrTime + test.TaxiIn + test.TaxiOut\", \"def season(x):\\n    if x in [12, 1, 2]:\\n        r...'season'] = test.Month.apply(lambda x: season(x))\", \"def timefl(x):\\n    begin = x['DepTime']\\n    end ... 1)\\ntest['FullTime'] = df.apply(timefl, axis = 1)\", 'df = shuffle(df)\\n\\nx_count, x_train = train_test_...dom_state=42)\\nprint(x_count.shape, x_train.shape)', 'import math\\ndef logit(x):\\n    return math.log(x ...   return logit(v.mean() + 0.00001) # guess why ?', \"day_mean = df.loc[:, ['DayOfWeek', 'target']].gr...'day_mean_target'}, inplace=True)\\nday_mean.head()\", \"month_mean = df.loc[:, ['Month', 'target']].grou...th_mean_target'}, inplace=True)\\nmonth_mean.head()\", 'import warnings\\nwarnings.filterwarnings(\"ignore\")', \"flight_c_volume = df.loc[:, ['target', 'UniqueCa...er_volume'].reshape(-1,1))\\nflight_c_volume.head()\", \"flight_volume = df.loc[:, ['target', 'TailNum']]...ight_volume'].reshape(-1,1))\\nflight_volume.head()\", \"season = x_count.loc[:, ['target', 'season']].gr...son_empirical_mean'}, inplace=True)\\nseason.head()\", \"un_carrier = x_count.loc[:, ['target', 'UniqueCa...empirical_mean'}, inplace=True)\\nun_carrier.head()\", \"origin = x_count.loc[:, ['target', 'Origin']].gr...gin_empirical_mean'}, inplace=True)\\norigin.head()\", \"dest = x_count.loc[:, ['target', 'Dest']].groupb...'dest_empirical_mean'}, inplace=True)\\ndest.head()\", ...], 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'MinMaxScaler': <class 'sklearn.preprocessing.data.MinMaxScaler'>, 'Out': {11:    DayOfWeek  day_mean_target\n0          1      ... 4        -0.840437\n4          5        -0.681012, 12:    Month  month_mean_target\n0      1          -0... 4          -0.947671\n4      5          -0.985007, 14:   UniqueCarrier  flight_carrier_volume\n0        ...  0.119449\n4            B6               0.156475, 15:   TailNum  flight_volume\n0  80009E       0.39037...3  80129E       0.407407\n4  80139E       0.398467, 16:    season  season_empirical_mean\n0    fall      ...       -0.770938\n3  winter              -0.562173, 17:   UniqueCarrier  un_carrier_empirical_mean\n0    ...948899\n4            B6                  -0.859630, 18: Empty DataFrame\nColumns: [index]\nIndex: [], 19:   Dest  dest_empirical_mean\n0  ABE            -0...            -0.737915\n4  ACK            -0.514413, 20:   TailNum  tailnum_empirical_mean\n0  80009E     ...       0.221726\n4  80139E                0.201238, 25:    DayOfWeek  day_mean_target\n0          1      ... 4        -0.840462\n4          5        -0.681037, ...}, '_':         Month  DayofMonth  DayOfWeek  DepTime  A...        0.285397       0  \n\n[5 rows x 23 columns], '_11':    DayOfWeek  day_mean_target\n0          1      ... 4        -0.840437\n4          5        -0.681012, '_12':    Month  month_mean_target\n0      1          -0... 4          -0.947671\n4      5          -0.985007, '_14':   UniqueCarrier  flight_carrier_volume\n0        ...  0.119449\n4            B6               0.156475, '_15':   TailNum  flight_volume\n0  80009E       0.39037...3  80129E       0.407407\n4  80139E       0.398467, '_16':    season  season_empirical_mean\n0    fall      ...       -0.770938\n3  winter              -0.562173, ...}\n   2863             finally:\n   2864                 # Reset our crash handler in place\n   2865                 sys.excepthook = old_excepthook\n   2866         except SystemExit as e:\n\n...........................................................................\nC:\\Users\\Даниил\\<ipython-input-44-f5a234f2c534> in <module>()\n      1 cv = cross_val_score(estimator=LogisticRegression(), \n      2                 X=x_train.drop('target', axis=1), \n      3                 y=x_train.target.values,\n      4                 cv=5, # you may use 3 or 5\n      5                 scoring='roc_auc', \n----> 6                 n_jobs=-1,)\n      7 print(cv.mean(), cv.std())\n      8 print(cv)\n\n...........................................................................\nA:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in cross_val_score(estimator=LogisticRegression(C=1.0, class_weight=None, dua...ol=0.0001,\n          verbose=0, warm_start=False), X=         Month  DayofMonth  DayOfWeek  DepTime  ...          0.372204  \n\n[1028281 rows x 22 columns], y=array([0, 0, 0, ..., 0, 0, 0], dtype=int64), groups=None, scoring='roc_auc', cv=5, n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs')\n    316     cv_results = cross_validate(estimator=estimator, X=X, y=y, groups=groups,\n    317                                 scoring={'score': scorer}, cv=cv,\n    318                                 return_train_score=False,\n    319                                 n_jobs=n_jobs, verbose=verbose,\n    320                                 fit_params=fit_params,\n--> 321                                 pre_dispatch=pre_dispatch)\n        pre_dispatch = '2*n_jobs'\n    322     return cv_results['test_score']\n    323 \n    324 \n    325 def _fit_and_score(estimator, X, y, scorer, train, test, verbose,\n\n...........................................................................\nA:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in cross_validate(estimator=LogisticRegression(C=1.0, class_weight=None, dua...ol=0.0001,\n          verbose=0, warm_start=False), X=         Month  DayofMonth  DayOfWeek  DepTime  ...          0.372204  \n\n[1028281 rows x 22 columns], y=array([0, 0, 0, ..., 0, 0, 0], dtype=int64), groups=None, scoring={'score': make_scorer(roc_auc_score, needs_threshold=True)}, cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', return_train_score=False)\n    190     scores = parallel(\n    191         delayed(_fit_and_score)(\n    192             clone(estimator), X, y, scorers, train, test, verbose, None,\n    193             fit_params, return_train_score=return_train_score,\n    194             return_times=True)\n--> 195         for train, test in cv.split(X, y, groups))\n        cv.split = <bound method StratifiedKFold.split of Stratifie...ld(n_splits=5, random_state=None, shuffle=False)>\n        X =          Month  DayofMonth  DayOfWeek  DepTime  ...          0.372204  \n\n[1028281 rows x 22 columns]\n        y = array([0, 0, 0, ..., 0, 0, 0], dtype=int64)\n        groups = None\n    196 \n    197     if return_train_score:\n    198         train_scores, test_scores, fit_times, score_times = zip(*scores)\n    199         train_scores = _aggregate_score_dicts(train_scores)\n\n...........................................................................\nA:\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object cross_validate.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Sat Feb 24 21:57:28 2018\nPID: 13836                            Python 3.6.2: A:\\Anaconda3\\python.exe\n...........................................................................\nA:\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (LogisticRegression(C=1.0, class_weight=None, dua...ol=0.0001,\n          verbose=0, warm_start=False),          Month  DayofMonth  DayOfWeek  DepTime  ...          0.372204  \n\n[1028281 rows x 22 columns], memmap([0, 0, 0, ..., 0, 0, 0], dtype=int64), {'score': make_scorer(roc_auc_score, needs_threshold=True)}, memmap([ 204912,  204921,  204923, ..., 1028278, 1028279, 1028280]), array([     0,      1,      2, ..., 205944, 205945, 205946]), 0, None, None), {'return_times': True, 'return_train_score': False})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nA:\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (LogisticRegression(C=1.0, class_weight=None, dua...ol=0.0001,\n          verbose=0, warm_start=False),          Month  DayofMonth  DayOfWeek  DepTime  ...          0.372204  \n\n[1028281 rows x 22 columns], memmap([0, 0, 0, ..., 0, 0, 0], dtype=int64), {'score': make_scorer(roc_auc_score, needs_threshold=True)}, memmap([ 204912,  204921,  204923, ..., 1028278, 1028279, 1028280]), array([     0,      1,      2, ..., 205944, 205945, 205946]), 0, None, None)\n        kwargs = {'return_times': True, 'return_train_score': False}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nA:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=LogisticRegression(C=1.0, class_weight=None, dua...ol=0.0001,\n          verbose=0, warm_start=False), X=         Month  DayofMonth  DayOfWeek  DepTime  ...          0.372204  \n\n[1028281 rows x 22 columns], y=memmap([0, 0, 0, ..., 0, 0, 0], dtype=int64), scorer={'score': make_scorer(roc_auc_score, needs_threshold=True)}, train=memmap([ 204912,  204921,  204923, ..., 1028278, 1028279, 1028280]), test=array([     0,      1,      2, ..., 205944, 205945, 205946]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, error_score='raise')\n    432 \n    433     try:\n    434         if y_train is None:\n    435             estimator.fit(X_train, **fit_params)\n    436         else:\n--> 437             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method LogisticRegression.fit of Logistic...l=0.0001,\n          verbose=0, warm_start=False)>\n        X_train =         Month  DayofMonth  DayOfWeek  DepTime  A...           0.372204  \n\n[822624 rows x 22 columns]\n        y_train = memmap([1, 1, 1, ..., 0, 0, 0], dtype=int64)\n        fit_params = {}\n    438 \n    439     except Exception as e:\n    440         # Note fit time as time until error\n    441         fit_time = time.time() - start_time\n\n...........................................................................\nA:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py in fit(self=LogisticRegression(C=1.0, class_weight=None, dua...ol=0.0001,\n          verbose=0, warm_start=False), X=        Month  DayofMonth  DayOfWeek  DepTime  A...           0.372204  \n\n[822624 rows x 22 columns], y=memmap([1, 1, 1, ..., 0, 0, 0], dtype=int64), sample_weight=None)\n   1211             _dtype = [np.float64, np.float32]\n   1212         else:\n   1213             _dtype = np.float64\n   1214 \n   1215         X, y = check_X_y(X, y, accept_sparse='csr', dtype=_dtype,\n-> 1216                          order=\"C\")\n   1217         check_classification_targets(y)\n   1218         self.classes_ = np.unique(y)\n   1219         n_samples, n_features = X.shape\n   1220 \n\n...........................................................................\nA:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py in check_X_y(X=        Month  DayofMonth  DayOfWeek  DepTime  A...           0.372204  \n\n[822624 rows x 22 columns], y=memmap([1, 1, 1, ..., 0, 0, 0], dtype=int64), accept_sparse='csr', dtype=<class 'numpy.float64'>, order='C', copy=False, force_all_finite=True, ensure_2d=True, allow_nd=False, multi_output=False, ensure_min_samples=1, ensure_min_features=1, y_numeric=False, warn_on_dtype=False, estimator=None)\n    537     y_converted : object\n    538         The converted and validated y.\n    539     \"\"\"\n    540     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n    541                     ensure_2d, allow_nd, ensure_min_samples,\n--> 542                     ensure_min_features, warn_on_dtype, estimator)\n        ensure_min_features = 1\n        warn_on_dtype = False\n        estimator = None\n    543     if multi_output:\n    544         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n    545                         dtype=None)\n    546     else:\n\n...........................................................................\nA:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py in check_array(array=array([[  1.        ,  27.        ,   7.        ...0.68103685,\n         -0.56387301,   0.37220361]]), accept_sparse='csr', dtype=<class 'numpy.float64'>, order='C', copy=False, force_all_finite=True, ensure_2d=True, allow_nd=False, ensure_min_samples=1, ensure_min_features=1, warn_on_dtype=False, estimator=None)\n    417             array = array.astype(np.float64)\n    418         if not allow_nd and array.ndim >= 3:\n    419             raise ValueError(\"Found array with dim %d. %s expected <= 2.\"\n    420                              % (array.ndim, estimator_name))\n    421         if force_all_finite:\n--> 422             _assert_all_finite(array)\n        array = array([[  1.        ,  27.        ,   7.        ...0.68103685,\n         -0.56387301,   0.37220361]])\n    423 \n    424     shape_repr = _shape_repr(array.shape)\n    425     if ensure_min_samples > 0:\n    426         n_samples = _num_samples(array)\n\n...........................................................................\nA:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py in _assert_all_finite(X=array([[  1.        ,  27.        ,   7.        ...0.68103685,\n         -0.56387301,   0.37220361]]))\n     38     # everything is finite; fall back to O(n) space np.isfinite to prevent\n     39     # false positives from overflow in sum method.\n     40     if (X.dtype.char in np.typecodes['AllFloat'] and not np.isfinite(X.sum())\n     41             and not np.isfinite(X).all()):\n     42         raise ValueError(\"Input contains NaN, infinity\"\n---> 43                          \" or a value too large for %r.\" % X.dtype)\n        X.dtype = dtype('float64')\n     44 \n     45 \n     46 def assert_all_finite(X):\n     47     \"\"\"Throw a ValueError if X contains NaN or infinity.\n\nValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"A:\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 350, in __call__\n    return self.func(*args, **kwargs)\n  File \"A:\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"A:\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"A:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 437, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"A:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py\", line 1216, in fit\n    order=\"C\")\n  File \"A:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 542, in check_X_y\n    ensure_min_features, warn_on_dtype, estimator)\n  File \"A:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 422, in check_array\n    _assert_all_finite(array)\n  File \"A:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 43, in _assert_all_finite\n    \" or a value too large for %r.\" % X.dtype)\nValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"A:\\Anaconda3\\lib\\multiprocessing\\pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"A:\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 359, in __call__\n    raise TransportableException(text, e_type)\nsklearn.externals.joblib.my_exceptions.TransportableException: TransportableException\n___________________________________________________________________________\nValueError                                         Sat Feb 24 21:57:28 2018\nPID: 13836                            Python 3.6.2: A:\\Anaconda3\\python.exe\n...........................................................................\nA:\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (LogisticRegression(C=1.0, class_weight=None, dua...ol=0.0001,\n          verbose=0, warm_start=False),          Month  DayofMonth  DayOfWeek  DepTime  ...          0.372204  \n\n[1028281 rows x 22 columns], memmap([0, 0, 0, ..., 0, 0, 0], dtype=int64), {'score': make_scorer(roc_auc_score, needs_threshold=True)}, memmap([ 204912,  204921,  204923, ..., 1028278, 1028279, 1028280]), array([     0,      1,      2, ..., 205944, 205945, 205946]), 0, None, None), {'return_times': True, 'return_train_score': False})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nA:\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (LogisticRegression(C=1.0, class_weight=None, dua...ol=0.0001,\n          verbose=0, warm_start=False),          Month  DayofMonth  DayOfWeek  DepTime  ...          0.372204  \n\n[1028281 rows x 22 columns], memmap([0, 0, 0, ..., 0, 0, 0], dtype=int64), {'score': make_scorer(roc_auc_score, needs_threshold=True)}, memmap([ 204912,  204921,  204923, ..., 1028278, 1028279, 1028280]), array([     0,      1,      2, ..., 205944, 205945, 205946]), 0, None, None)\n        kwargs = {'return_times': True, 'return_train_score': False}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nA:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=LogisticRegression(C=1.0, class_weight=None, dua...ol=0.0001,\n          verbose=0, warm_start=False), X=         Month  DayofMonth  DayOfWeek  DepTime  ...          0.372204  \n\n[1028281 rows x 22 columns], y=memmap([0, 0, 0, ..., 0, 0, 0], dtype=int64), scorer={'score': make_scorer(roc_auc_score, needs_threshold=True)}, train=memmap([ 204912,  204921,  204923, ..., 1028278, 1028279, 1028280]), test=array([     0,      1,      2, ..., 205944, 205945, 205946]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, error_score='raise')\n    432 \n    433     try:\n    434         if y_train is None:\n    435             estimator.fit(X_train, **fit_params)\n    436         else:\n--> 437             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method LogisticRegression.fit of Logistic...l=0.0001,\n          verbose=0, warm_start=False)>\n        X_train =         Month  DayofMonth  DayOfWeek  DepTime  A...           0.372204  \n\n[822624 rows x 22 columns]\n        y_train = memmap([1, 1, 1, ..., 0, 0, 0], dtype=int64)\n        fit_params = {}\n    438 \n    439     except Exception as e:\n    440         # Note fit time as time until error\n    441         fit_time = time.time() - start_time\n\n...........................................................................\nA:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py in fit(self=LogisticRegression(C=1.0, class_weight=None, dua...ol=0.0001,\n          verbose=0, warm_start=False), X=        Month  DayofMonth  DayOfWeek  DepTime  A...           0.372204  \n\n[822624 rows x 22 columns], y=memmap([1, 1, 1, ..., 0, 0, 0], dtype=int64), sample_weight=None)\n   1211             _dtype = [np.float64, np.float32]\n   1212         else:\n   1213             _dtype = np.float64\n   1214 \n   1215         X, y = check_X_y(X, y, accept_sparse='csr', dtype=_dtype,\n-> 1216                          order=\"C\")\n   1217         check_classification_targets(y)\n   1218         self.classes_ = np.unique(y)\n   1219         n_samples, n_features = X.shape\n   1220 \n\n...........................................................................\nA:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py in check_X_y(X=        Month  DayofMonth  DayOfWeek  DepTime  A...           0.372204  \n\n[822624 rows x 22 columns], y=memmap([1, 1, 1, ..., 0, 0, 0], dtype=int64), accept_sparse='csr', dtype=<class 'numpy.float64'>, order='C', copy=False, force_all_finite=True, ensure_2d=True, allow_nd=False, multi_output=False, ensure_min_samples=1, ensure_min_features=1, y_numeric=False, warn_on_dtype=False, estimator=None)\n    537     y_converted : object\n    538         The converted and validated y.\n    539     \"\"\"\n    540     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n    541                     ensure_2d, allow_nd, ensure_min_samples,\n--> 542                     ensure_min_features, warn_on_dtype, estimator)\n        ensure_min_features = 1\n        warn_on_dtype = False\n        estimator = None\n    543     if multi_output:\n    544         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n    545                         dtype=None)\n    546     else:\n\n...........................................................................\nA:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py in check_array(array=array([[  1.        ,  27.        ,   7.        ...0.68103685,\n         -0.56387301,   0.37220361]]), accept_sparse='csr', dtype=<class 'numpy.float64'>, order='C', copy=False, force_all_finite=True, ensure_2d=True, allow_nd=False, ensure_min_samples=1, ensure_min_features=1, warn_on_dtype=False, estimator=None)\n    417             array = array.astype(np.float64)\n    418         if not allow_nd and array.ndim >= 3:\n    419             raise ValueError(\"Found array with dim %d. %s expected <= 2.\"\n    420                              % (array.ndim, estimator_name))\n    421         if force_all_finite:\n--> 422             _assert_all_finite(array)\n        array = array([[  1.        ,  27.        ,   7.        ...0.68103685,\n         -0.56387301,   0.37220361]])\n    423 \n    424     shape_repr = _shape_repr(array.shape)\n    425     if ensure_min_samples > 0:\n    426         n_samples = _num_samples(array)\n\n...........................................................................\nA:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py in _assert_all_finite(X=array([[  1.        ,  27.        ,   7.        ...0.68103685,\n         -0.56387301,   0.37220361]]))\n     38     # everything is finite; fall back to O(n) space np.isfinite to prevent\n     39     # false positives from overflow in sum method.\n     40     if (X.dtype.char in np.typecodes['AllFloat'] and not np.isfinite(X.sum())\n     41             and not np.isfinite(X).all()):\n     42         raise ValueError(\"Input contains NaN, infinity\"\n---> 43                          \" or a value too large for %r.\" % X.dtype)\n        X.dtype = dtype('float64')\n     44 \n     45 \n     46 def assert_all_finite(X):\n     47     \"\"\"Throw a ValueError if X contains NaN or infinity.\n\nValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n___________________________________________________________________________\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTransportableException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32mA:\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    700\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mA:\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    643\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 644\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    645\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nValueError                                         Sat Feb 24 21:57:28 2018\nPID: 13836                            Python 3.6.2: A:\\Anaconda3\\python.exe\n...........................................................................\nA:\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (LogisticRegression(C=1.0, class_weight=None, dua...ol=0.0001,\n          verbose=0, warm_start=False),          Month  DayofMonth  DayOfWeek  DepTime  ...          0.372204  \n\n[1028281 rows x 22 columns], memmap([0, 0, 0, ..., 0, 0, 0], dtype=int64), {'score': make_scorer(roc_auc_score, needs_threshold=True)}, memmap([ 204912,  204921,  204923, ..., 1028278, 1028279, 1028280]), array([     0,      1,      2, ..., 205944, 205945, 205946]), 0, None, None), {'return_times': True, 'return_train_score': False})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nA:\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (LogisticRegression(C=1.0, class_weight=None, dua...ol=0.0001,\n          verbose=0, warm_start=False),          Month  DayofMonth  DayOfWeek  DepTime  ...          0.372204  \n\n[1028281 rows x 22 columns], memmap([0, 0, 0, ..., 0, 0, 0], dtype=int64), {'score': make_scorer(roc_auc_score, needs_threshold=True)}, memmap([ 204912,  204921,  204923, ..., 1028278, 1028279, 1028280]), array([     0,      1,      2, ..., 205944, 205945, 205946]), 0, None, None)\n        kwargs = {'return_times': True, 'return_train_score': False}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nA:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=LogisticRegression(C=1.0, class_weight=None, dua...ol=0.0001,\n          verbose=0, warm_start=False), X=         Month  DayofMonth  DayOfWeek  DepTime  ...          0.372204  \n\n[1028281 rows x 22 columns], y=memmap([0, 0, 0, ..., 0, 0, 0], dtype=int64), scorer={'score': make_scorer(roc_auc_score, needs_threshold=True)}, train=memmap([ 204912,  204921,  204923, ..., 1028278, 1028279, 1028280]), test=array([     0,      1,      2, ..., 205944, 205945, 205946]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, error_score='raise')\n    432 \n    433     try:\n    434         if y_train is None:\n    435             estimator.fit(X_train, **fit_params)\n    436         else:\n--> 437             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method LogisticRegression.fit of Logistic...l=0.0001,\n          verbose=0, warm_start=False)>\n        X_train =         Month  DayofMonth  DayOfWeek  DepTime  A...           0.372204  \n\n[822624 rows x 22 columns]\n        y_train = memmap([1, 1, 1, ..., 0, 0, 0], dtype=int64)\n        fit_params = {}\n    438 \n    439     except Exception as e:\n    440         # Note fit time as time until error\n    441         fit_time = time.time() - start_time\n\n...........................................................................\nA:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py in fit(self=LogisticRegression(C=1.0, class_weight=None, dua...ol=0.0001,\n          verbose=0, warm_start=False), X=        Month  DayofMonth  DayOfWeek  DepTime  A...           0.372204  \n\n[822624 rows x 22 columns], y=memmap([1, 1, 1, ..., 0, 0, 0], dtype=int64), sample_weight=None)\n   1211             _dtype = [np.float64, np.float32]\n   1212         else:\n   1213             _dtype = np.float64\n   1214 \n   1215         X, y = check_X_y(X, y, accept_sparse='csr', dtype=_dtype,\n-> 1216                          order=\"C\")\n   1217         check_classification_targets(y)\n   1218         self.classes_ = np.unique(y)\n   1219         n_samples, n_features = X.shape\n   1220 \n\n...........................................................................\nA:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py in check_X_y(X=        Month  DayofMonth  DayOfWeek  DepTime  A...           0.372204  \n\n[822624 rows x 22 columns], y=memmap([1, 1, 1, ..., 0, 0, 0], dtype=int64), accept_sparse='csr', dtype=<class 'numpy.float64'>, order='C', copy=False, force_all_finite=True, ensure_2d=True, allow_nd=False, multi_output=False, ensure_min_samples=1, ensure_min_features=1, y_numeric=False, warn_on_dtype=False, estimator=None)\n    537     y_converted : object\n    538         The converted and validated y.\n    539     \"\"\"\n    540     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n    541                     ensure_2d, allow_nd, ensure_min_samples,\n--> 542                     ensure_min_features, warn_on_dtype, estimator)\n        ensure_min_features = 1\n        warn_on_dtype = False\n        estimator = None\n    543     if multi_output:\n    544         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n    545                         dtype=None)\n    546     else:\n\n...........................................................................\nA:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py in check_array(array=array([[  1.        ,  27.        ,   7.        ...0.68103685,\n         -0.56387301,   0.37220361]]), accept_sparse='csr', dtype=<class 'numpy.float64'>, order='C', copy=False, force_all_finite=True, ensure_2d=True, allow_nd=False, ensure_min_samples=1, ensure_min_features=1, warn_on_dtype=False, estimator=None)\n    417             array = array.astype(np.float64)\n    418         if not allow_nd and array.ndim >= 3:\n    419             raise ValueError(\"Found array with dim %d. %s expected <= 2.\"\n    420                              % (array.ndim, estimator_name))\n    421         if force_all_finite:\n--> 422             _assert_all_finite(array)\n        array = array([[  1.        ,  27.        ,   7.        ...0.68103685,\n         -0.56387301,   0.37220361]])\n    423 \n    424     shape_repr = _shape_repr(array.shape)\n    425     if ensure_min_samples > 0:\n    426         n_samples = _num_samples(array)\n\n...........................................................................\nA:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py in _assert_all_finite(X=array([[  1.        ,  27.        ,   7.        ...0.68103685,\n         -0.56387301,   0.37220361]]))\n     38     # everything is finite; fall back to O(n) space np.isfinite to prevent\n     39     # false positives from overflow in sum method.\n     40     if (X.dtype.char in np.typecodes['AllFloat'] and not np.isfinite(X.sum())\n     41             and not np.isfinite(X).all()):\n     42         raise ValueError(\"Input contains NaN, infinity\"\n---> 43                          \" or a value too large for %r.\" % X.dtype)\n        X.dtype = dtype('float64')\n     44 \n     45 \n     46 def assert_all_finite(X):\n     47     \"\"\"Throw a ValueError if X contains NaN or infinity.\n\nValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mJoblibValueError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-f5a234f2c534>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m                 \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;31m# you may use 3 or 5\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                 \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'roc_auc'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m                 n_jobs=-1,)\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mA:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[0;32m    319\u001b[0m                                 \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 321\u001b[1;33m                                 pre_dispatch=pre_dispatch)\n\u001b[0m\u001b[0;32m    322\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mA:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score)\u001b[0m\n\u001b[0;32m    193\u001b[0m             \u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_train_score\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m             return_times=True)\n\u001b[1;32m--> 195\u001b[1;33m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[0;32m    196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mA:\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    787\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 789\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    790\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mA:\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    738\u001b[0m                     \u001b[0mexception\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexception_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    739\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 740\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    742\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mJoblibValueError\u001b[0m: JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\nA:\\Anaconda3\\lib\\runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\nA:\\Anaconda3\\lib\\runpy.py in _run_code(code=<code object <module> at 0x000001C59263DC90, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'A:\\Anaconda3\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'A:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'A:\\\\Anaconda3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x000001C59263DC90, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'A:\\Anaconda3\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'A:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'A:\\\\Anaconda3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\nA:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\nA:\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\nA:\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    472             return self.subapp.start()\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         try:\n--> 477             ioloop.IOLoop.instance().start()\n    478         except KeyboardInterrupt:\n    479             pass\n    480 \n    481 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\nA:\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\nA:\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\nA:\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\nA:\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\nA:\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\nA:\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\nA:\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\nA:\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\nA:\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'cv = cross_val_score(estimator=LogisticRegressio... n_jobs=-1,)\\nprint(cv.mean(), cv.std())\\nprint(cv)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 2, 24, 18, 55, 57, 492250, tzinfo=tzutc()), 'msg_id': '477830FF1DBF499885B7307851B82494', 'msg_type': 'execute_request', 'session': '6D8CFF996F07448DB708A867FE8C7AC1', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '477830FF1DBF499885B7307851B82494', 'msg_type': 'execute_request', 'parent_header': {}})\n    230             self.log.warn(\"Unknown message type: %r\", msg_type)\n    231         else:\n    232             self.log.debug(\"%s: %s\", msg_type, msg)\n    233             self.pre_handler_hook()\n    234             try:\n--> 235                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'6D8CFF996F07448DB708A867FE8C7AC1']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'cv = cross_val_score(estimator=LogisticRegressio... n_jobs=-1,)\\nprint(cv.mean(), cv.std())\\nprint(cv)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 2, 24, 18, 55, 57, 492250, tzinfo=tzutc()), 'msg_id': '477830FF1DBF499885B7307851B82494', 'msg_type': 'execute_request', 'session': '6D8CFF996F07448DB708A867FE8C7AC1', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '477830FF1DBF499885B7307851B82494', 'msg_type': 'execute_request', 'parent_header': {}}\n    236             except Exception:\n    237                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    238             finally:\n    239                 self.post_handler_hook()\n\n...........................................................................\nA:\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'6D8CFF996F07448DB708A867FE8C7AC1'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'cv = cross_val_score(estimator=LogisticRegressio... n_jobs=-1,)\\nprint(cv.mean(), cv.std())\\nprint(cv)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 2, 24, 18, 55, 57, 492250, tzinfo=tzutc()), 'msg_id': '477830FF1DBF499885B7307851B82494', 'msg_type': 'execute_request', 'session': '6D8CFF996F07448DB708A867FE8C7AC1', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '477830FF1DBF499885B7307851B82494', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\nA:\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='cv = cross_val_score(estimator=LogisticRegressio... n_jobs=-1,)\\nprint(cv.mean(), cv.std())\\nprint(cv)', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = 'cv = cross_val_score(estimator=LogisticRegressio... n_jobs=-1,)\\nprint(cv.mean(), cv.std())\\nprint(cv)'\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\nA:\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('cv = cross_val_score(estimator=LogisticRegressio... n_jobs=-1,)\\nprint(cv.mean(), cv.std())\\nprint(cv)',), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('cv = cross_val_score(estimator=LogisticRegressio... n_jobs=-1,)\\nprint(cv.mean(), cv.std())\\nprint(cv)',)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\nA:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='cv = cross_val_score(estimator=LogisticRegressio... n_jobs=-1,)\\nprint(cv.mean(), cv.std())\\nprint(cv)', store_history=True, silent=False, shell_futures=True)\n   2693                 self.displayhook.exec_result = result\n   2694 \n   2695                 # Execute the user code\n   2696                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2697                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2698                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2699                 \n   2700                 self.last_execution_succeeded = not has_raised\n   2701 \n   2702                 # Reset this so later displayed values do not modify the\n\n...........................................................................\nA:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Expr object>, <_ast.Expr object>], cell_name='<ipython-input-44-f5a234f2c534>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 1c581f23550, executio..._before_exec=None error_in_exec=None result=None>)\n   2797 \n   2798         try:\n   2799             for i, node in enumerate(to_run_exec):\n   2800                 mod = ast.Module([node])\n   2801                 code = compiler(mod, cell_name, \"exec\")\n-> 2802                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x000001C581CF9C00, file \"<ipython-input-44-f5a234f2c534>\", line 1>\n        result = <ExecutionResult object at 1c581f23550, executio..._before_exec=None error_in_exec=None result=None>\n   2803                     return True\n   2804 \n   2805             for i, node in enumerate(to_run_interactive):\n   2806                 mod = ast.Interactive([node])\n\n...........................................................................\nA:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x000001C581CF9C00, file \"<ipython-input-44-f5a234f2c534>\", line 1>, result=<ExecutionResult object at 1c581f23550, executio..._before_exec=None error_in_exec=None result=None>)\n   2857         outflag = True  # happens in more places, so it's easier as default\n   2858         try:\n   2859             try:\n   2860                 self.hooks.pre_run_code_hook()\n   2861                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2862                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x000001C581CF9C00, file \"<ipython-input-44-f5a234f2c534>\", line 1>\n        self.user_global_ns = {'In': ['', 'import pandas as pd\\nimport numpy as np\\nfrom skle...rt MinMaxScaler\\nfrom sklearn.utils import shuffle', 'scaler = MinMaxScaler()', \"df = pd.read_csv('train_dataset.csv')\\ndf = df[(~...t.Id.values\\ntest.drop('Id', axis=1, inplace=True)\", \"df['speed'] = (60 * df.Distance/df.AirTime).repl...st.AirTime).replace([np.nan, np.inf, -np.inf], 0)\", \"df['diff_arr_dep_time'] = df.ArrTime - df.DepTim...diff_arr_dep_time'] = test.ArrTime - test.DepTime\", \"df['elapsed_time'] = df.ArrTime + df.TaxiIn + df...ime'] = test.ArrTime + test.TaxiIn + test.TaxiOut\", \"def season(x):\\n    if x in [12, 1, 2]:\\n        r...'season'] = test.Month.apply(lambda x: season(x))\", \"def timefl(x):\\n    begin = x['DepTime']\\n    end ... 1)\\ntest['FullTime'] = df.apply(timefl, axis = 1)\", 'df = shuffle(df)\\n\\nx_count, x_train = train_test_...dom_state=42)\\nprint(x_count.shape, x_train.shape)', 'import math\\ndef logit(x):\\n    return math.log(x ...   return logit(v.mean() + 0.00001) # guess why ?', \"day_mean = df.loc[:, ['DayOfWeek', 'target']].gr...'day_mean_target'}, inplace=True)\\nday_mean.head()\", \"month_mean = df.loc[:, ['Month', 'target']].grou...th_mean_target'}, inplace=True)\\nmonth_mean.head()\", 'import warnings\\nwarnings.filterwarnings(\"ignore\")', \"flight_c_volume = df.loc[:, ['target', 'UniqueCa...er_volume'].reshape(-1,1))\\nflight_c_volume.head()\", \"flight_volume = df.loc[:, ['target', 'TailNum']]...ight_volume'].reshape(-1,1))\\nflight_volume.head()\", \"season = x_count.loc[:, ['target', 'season']].gr...son_empirical_mean'}, inplace=True)\\nseason.head()\", \"un_carrier = x_count.loc[:, ['target', 'UniqueCa...empirical_mean'}, inplace=True)\\nun_carrier.head()\", \"origin = x_count.loc[:, ['target', 'Origin']].gr...gin_empirical_mean'}, inplace=True)\\norigin.head()\", \"dest = x_count.loc[:, ['target', 'Dest']].groupb...'dest_empirical_mean'}, inplace=True)\\ndest.head()\", ...], 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'MinMaxScaler': <class 'sklearn.preprocessing.data.MinMaxScaler'>, 'Out': {11:    DayOfWeek  day_mean_target\n0          1      ... 4        -0.840437\n4          5        -0.681012, 12:    Month  month_mean_target\n0      1          -0... 4          -0.947671\n4      5          -0.985007, 14:   UniqueCarrier  flight_carrier_volume\n0        ...  0.119449\n4            B6               0.156475, 15:   TailNum  flight_volume\n0  80009E       0.39037...3  80129E       0.407407\n4  80139E       0.398467, 16:    season  season_empirical_mean\n0    fall      ...       -0.770938\n3  winter              -0.562173, 17:   UniqueCarrier  un_carrier_empirical_mean\n0    ...948899\n4            B6                  -0.859630, 18: Empty DataFrame\nColumns: [index]\nIndex: [], 19:   Dest  dest_empirical_mean\n0  ABE            -0...            -0.737915\n4  ACK            -0.514413, 20:   TailNum  tailnum_empirical_mean\n0  80009E     ...       0.221726\n4  80139E                0.201238, 25:    DayOfWeek  day_mean_target\n0          1      ... 4        -0.840462\n4          5        -0.681037, ...}, '_':         Month  DayofMonth  DayOfWeek  DepTime  A...        0.285397       0  \n\n[5 rows x 23 columns], '_11':    DayOfWeek  day_mean_target\n0          1      ... 4        -0.840437\n4          5        -0.681012, '_12':    Month  month_mean_target\n0      1          -0... 4          -0.947671\n4      5          -0.985007, '_14':   UniqueCarrier  flight_carrier_volume\n0        ...  0.119449\n4            B6               0.156475, '_15':   TailNum  flight_volume\n0  80009E       0.39037...3  80129E       0.407407\n4  80139E       0.398467, '_16':    season  season_empirical_mean\n0    fall      ...       -0.770938\n3  winter              -0.562173, ...}\n        self.user_ns = {'In': ['', 'import pandas as pd\\nimport numpy as np\\nfrom skle...rt MinMaxScaler\\nfrom sklearn.utils import shuffle', 'scaler = MinMaxScaler()', \"df = pd.read_csv('train_dataset.csv')\\ndf = df[(~...t.Id.values\\ntest.drop('Id', axis=1, inplace=True)\", \"df['speed'] = (60 * df.Distance/df.AirTime).repl...st.AirTime).replace([np.nan, np.inf, -np.inf], 0)\", \"df['diff_arr_dep_time'] = df.ArrTime - df.DepTim...diff_arr_dep_time'] = test.ArrTime - test.DepTime\", \"df['elapsed_time'] = df.ArrTime + df.TaxiIn + df...ime'] = test.ArrTime + test.TaxiIn + test.TaxiOut\", \"def season(x):\\n    if x in [12, 1, 2]:\\n        r...'season'] = test.Month.apply(lambda x: season(x))\", \"def timefl(x):\\n    begin = x['DepTime']\\n    end ... 1)\\ntest['FullTime'] = df.apply(timefl, axis = 1)\", 'df = shuffle(df)\\n\\nx_count, x_train = train_test_...dom_state=42)\\nprint(x_count.shape, x_train.shape)', 'import math\\ndef logit(x):\\n    return math.log(x ...   return logit(v.mean() + 0.00001) # guess why ?', \"day_mean = df.loc[:, ['DayOfWeek', 'target']].gr...'day_mean_target'}, inplace=True)\\nday_mean.head()\", \"month_mean = df.loc[:, ['Month', 'target']].grou...th_mean_target'}, inplace=True)\\nmonth_mean.head()\", 'import warnings\\nwarnings.filterwarnings(\"ignore\")', \"flight_c_volume = df.loc[:, ['target', 'UniqueCa...er_volume'].reshape(-1,1))\\nflight_c_volume.head()\", \"flight_volume = df.loc[:, ['target', 'TailNum']]...ight_volume'].reshape(-1,1))\\nflight_volume.head()\", \"season = x_count.loc[:, ['target', 'season']].gr...son_empirical_mean'}, inplace=True)\\nseason.head()\", \"un_carrier = x_count.loc[:, ['target', 'UniqueCa...empirical_mean'}, inplace=True)\\nun_carrier.head()\", \"origin = x_count.loc[:, ['target', 'Origin']].gr...gin_empirical_mean'}, inplace=True)\\norigin.head()\", \"dest = x_count.loc[:, ['target', 'Dest']].groupb...'dest_empirical_mean'}, inplace=True)\\ndest.head()\", ...], 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'MinMaxScaler': <class 'sklearn.preprocessing.data.MinMaxScaler'>, 'Out': {11:    DayOfWeek  day_mean_target\n0          1      ... 4        -0.840437\n4          5        -0.681012, 12:    Month  month_mean_target\n0      1          -0... 4          -0.947671\n4      5          -0.985007, 14:   UniqueCarrier  flight_carrier_volume\n0        ...  0.119449\n4            B6               0.156475, 15:   TailNum  flight_volume\n0  80009E       0.39037...3  80129E       0.407407\n4  80139E       0.398467, 16:    season  season_empirical_mean\n0    fall      ...       -0.770938\n3  winter              -0.562173, 17:   UniqueCarrier  un_carrier_empirical_mean\n0    ...948899\n4            B6                  -0.859630, 18: Empty DataFrame\nColumns: [index]\nIndex: [], 19:   Dest  dest_empirical_mean\n0  ABE            -0...            -0.737915\n4  ACK            -0.514413, 20:   TailNum  tailnum_empirical_mean\n0  80009E     ...       0.221726\n4  80139E                0.201238, 25:    DayOfWeek  day_mean_target\n0          1      ... 4        -0.840462\n4          5        -0.681037, ...}, '_':         Month  DayofMonth  DayOfWeek  DepTime  A...        0.285397       0  \n\n[5 rows x 23 columns], '_11':    DayOfWeek  day_mean_target\n0          1      ... 4        -0.840437\n4          5        -0.681012, '_12':    Month  month_mean_target\n0      1          -0... 4          -0.947671\n4      5          -0.985007, '_14':   UniqueCarrier  flight_carrier_volume\n0        ...  0.119449\n4            B6               0.156475, '_15':   TailNum  flight_volume\n0  80009E       0.39037...3  80129E       0.407407\n4  80139E       0.398467, '_16':    season  season_empirical_mean\n0    fall      ...       -0.770938\n3  winter              -0.562173, ...}\n   2863             finally:\n   2864                 # Reset our crash handler in place\n   2865                 sys.excepthook = old_excepthook\n   2866         except SystemExit as e:\n\n...........................................................................\nC:\\Users\\Даниил\\<ipython-input-44-f5a234f2c534> in <module>()\n      1 cv = cross_val_score(estimator=LogisticRegression(), \n      2                 X=x_train.drop('target', axis=1), \n      3                 y=x_train.target.values,\n      4                 cv=5, # you may use 3 or 5\n      5                 scoring='roc_auc', \n----> 6                 n_jobs=-1,)\n      7 print(cv.mean(), cv.std())\n      8 print(cv)\n\n...........................................................................\nA:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in cross_val_score(estimator=LogisticRegression(C=1.0, class_weight=None, dua...ol=0.0001,\n          verbose=0, warm_start=False), X=         Month  DayofMonth  DayOfWeek  DepTime  ...          0.372204  \n\n[1028281 rows x 22 columns], y=array([0, 0, 0, ..., 0, 0, 0], dtype=int64), groups=None, scoring='roc_auc', cv=5, n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs')\n    316     cv_results = cross_validate(estimator=estimator, X=X, y=y, groups=groups,\n    317                                 scoring={'score': scorer}, cv=cv,\n    318                                 return_train_score=False,\n    319                                 n_jobs=n_jobs, verbose=verbose,\n    320                                 fit_params=fit_params,\n--> 321                                 pre_dispatch=pre_dispatch)\n        pre_dispatch = '2*n_jobs'\n    322     return cv_results['test_score']\n    323 \n    324 \n    325 def _fit_and_score(estimator, X, y, scorer, train, test, verbose,\n\n...........................................................................\nA:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in cross_validate(estimator=LogisticRegression(C=1.0, class_weight=None, dua...ol=0.0001,\n          verbose=0, warm_start=False), X=         Month  DayofMonth  DayOfWeek  DepTime  ...          0.372204  \n\n[1028281 rows x 22 columns], y=array([0, 0, 0, ..., 0, 0, 0], dtype=int64), groups=None, scoring={'score': make_scorer(roc_auc_score, needs_threshold=True)}, cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', return_train_score=False)\n    190     scores = parallel(\n    191         delayed(_fit_and_score)(\n    192             clone(estimator), X, y, scorers, train, test, verbose, None,\n    193             fit_params, return_train_score=return_train_score,\n    194             return_times=True)\n--> 195         for train, test in cv.split(X, y, groups))\n        cv.split = <bound method StratifiedKFold.split of Stratifie...ld(n_splits=5, random_state=None, shuffle=False)>\n        X =          Month  DayofMonth  DayOfWeek  DepTime  ...          0.372204  \n\n[1028281 rows x 22 columns]\n        y = array([0, 0, 0, ..., 0, 0, 0], dtype=int64)\n        groups = None\n    196 \n    197     if return_train_score:\n    198         train_scores, test_scores, fit_times, score_times = zip(*scores)\n    199         train_scores = _aggregate_score_dicts(train_scores)\n\n...........................................................................\nA:\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object cross_validate.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Sat Feb 24 21:57:28 2018\nPID: 13836                            Python 3.6.2: A:\\Anaconda3\\python.exe\n...........................................................................\nA:\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (LogisticRegression(C=1.0, class_weight=None, dua...ol=0.0001,\n          verbose=0, warm_start=False),          Month  DayofMonth  DayOfWeek  DepTime  ...          0.372204  \n\n[1028281 rows x 22 columns], memmap([0, 0, 0, ..., 0, 0, 0], dtype=int64), {'score': make_scorer(roc_auc_score, needs_threshold=True)}, memmap([ 204912,  204921,  204923, ..., 1028278, 1028279, 1028280]), array([     0,      1,      2, ..., 205944, 205945, 205946]), 0, None, None), {'return_times': True, 'return_train_score': False})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nA:\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (LogisticRegression(C=1.0, class_weight=None, dua...ol=0.0001,\n          verbose=0, warm_start=False),          Month  DayofMonth  DayOfWeek  DepTime  ...          0.372204  \n\n[1028281 rows x 22 columns], memmap([0, 0, 0, ..., 0, 0, 0], dtype=int64), {'score': make_scorer(roc_auc_score, needs_threshold=True)}, memmap([ 204912,  204921,  204923, ..., 1028278, 1028279, 1028280]), array([     0,      1,      2, ..., 205944, 205945, 205946]), 0, None, None)\n        kwargs = {'return_times': True, 'return_train_score': False}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nA:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=LogisticRegression(C=1.0, class_weight=None, dua...ol=0.0001,\n          verbose=0, warm_start=False), X=         Month  DayofMonth  DayOfWeek  DepTime  ...          0.372204  \n\n[1028281 rows x 22 columns], y=memmap([0, 0, 0, ..., 0, 0, 0], dtype=int64), scorer={'score': make_scorer(roc_auc_score, needs_threshold=True)}, train=memmap([ 204912,  204921,  204923, ..., 1028278, 1028279, 1028280]), test=array([     0,      1,      2, ..., 205944, 205945, 205946]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, error_score='raise')\n    432 \n    433     try:\n    434         if y_train is None:\n    435             estimator.fit(X_train, **fit_params)\n    436         else:\n--> 437             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method LogisticRegression.fit of Logistic...l=0.0001,\n          verbose=0, warm_start=False)>\n        X_train =         Month  DayofMonth  DayOfWeek  DepTime  A...           0.372204  \n\n[822624 rows x 22 columns]\n        y_train = memmap([1, 1, 1, ..., 0, 0, 0], dtype=int64)\n        fit_params = {}\n    438 \n    439     except Exception as e:\n    440         # Note fit time as time until error\n    441         fit_time = time.time() - start_time\n\n...........................................................................\nA:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py in fit(self=LogisticRegression(C=1.0, class_weight=None, dua...ol=0.0001,\n          verbose=0, warm_start=False), X=        Month  DayofMonth  DayOfWeek  DepTime  A...           0.372204  \n\n[822624 rows x 22 columns], y=memmap([1, 1, 1, ..., 0, 0, 0], dtype=int64), sample_weight=None)\n   1211             _dtype = [np.float64, np.float32]\n   1212         else:\n   1213             _dtype = np.float64\n   1214 \n   1215         X, y = check_X_y(X, y, accept_sparse='csr', dtype=_dtype,\n-> 1216                          order=\"C\")\n   1217         check_classification_targets(y)\n   1218         self.classes_ = np.unique(y)\n   1219         n_samples, n_features = X.shape\n   1220 \n\n...........................................................................\nA:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py in check_X_y(X=        Month  DayofMonth  DayOfWeek  DepTime  A...           0.372204  \n\n[822624 rows x 22 columns], y=memmap([1, 1, 1, ..., 0, 0, 0], dtype=int64), accept_sparse='csr', dtype=<class 'numpy.float64'>, order='C', copy=False, force_all_finite=True, ensure_2d=True, allow_nd=False, multi_output=False, ensure_min_samples=1, ensure_min_features=1, y_numeric=False, warn_on_dtype=False, estimator=None)\n    537     y_converted : object\n    538         The converted and validated y.\n    539     \"\"\"\n    540     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n    541                     ensure_2d, allow_nd, ensure_min_samples,\n--> 542                     ensure_min_features, warn_on_dtype, estimator)\n        ensure_min_features = 1\n        warn_on_dtype = False\n        estimator = None\n    543     if multi_output:\n    544         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n    545                         dtype=None)\n    546     else:\n\n...........................................................................\nA:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py in check_array(array=array([[  1.        ,  27.        ,   7.        ...0.68103685,\n         -0.56387301,   0.37220361]]), accept_sparse='csr', dtype=<class 'numpy.float64'>, order='C', copy=False, force_all_finite=True, ensure_2d=True, allow_nd=False, ensure_min_samples=1, ensure_min_features=1, warn_on_dtype=False, estimator=None)\n    417             array = array.astype(np.float64)\n    418         if not allow_nd and array.ndim >= 3:\n    419             raise ValueError(\"Found array with dim %d. %s expected <= 2.\"\n    420                              % (array.ndim, estimator_name))\n    421         if force_all_finite:\n--> 422             _assert_all_finite(array)\n        array = array([[  1.        ,  27.        ,   7.        ...0.68103685,\n         -0.56387301,   0.37220361]])\n    423 \n    424     shape_repr = _shape_repr(array.shape)\n    425     if ensure_min_samples > 0:\n    426         n_samples = _num_samples(array)\n\n...........................................................................\nA:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py in _assert_all_finite(X=array([[  1.        ,  27.        ,   7.        ...0.68103685,\n         -0.56387301,   0.37220361]]))\n     38     # everything is finite; fall back to O(n) space np.isfinite to prevent\n     39     # false positives from overflow in sum method.\n     40     if (X.dtype.char in np.typecodes['AllFloat'] and not np.isfinite(X.sum())\n     41             and not np.isfinite(X).all()):\n     42         raise ValueError(\"Input contains NaN, infinity\"\n---> 43                          \" or a value too large for %r.\" % X.dtype)\n        X.dtype = dtype('float64')\n     44 \n     45 \n     46 def assert_all_finite(X):\n     47     \"\"\"Throw a ValueError if X contains NaN or infinity.\n\nValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "cv = cross_val_score(estimator=LogisticRegression(), \n",
    "                X=x_train.drop('target', axis=1), \n",
    "                y=x_train.target.values,\n",
    "                cv=5, # you may use 3 or 5\n",
    "                scoring='roc_auc', \n",
    "                n_jobs=-1,)\n",
    "print(cv.mean(), cv.std())\n",
    "print(cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = LogisticRegression(C=1.0)\n",
    "clf.fit(x_train.drop('target', axis=1), x_train.target.values)\n",
    "submission = clf.predict_proba(test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3504864,)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3504864,)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame({'Id': test_ids, 'Prediction1': submission}).to_csv('mean_target_mining_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
